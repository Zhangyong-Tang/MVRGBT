# Motivation

![8ceb2c866b3b579fffd9f52826f6859](https://github.com/user-attachments/assets/db23fed8-8052-4a77-a32a-cef4b4e9fb3d)

# üç∞Contributions
(1) A new benchmark, MV-RGBT, is collected to make it representative of multi-modal warranting scenarios, filling the gap between the data in current benchmarks and imaging conditions which motivate RGBT tracking.

(2) A new problem, `when to fuse', is posed to develop reliable fusion strategies for RGBT trackers, as in MMW scenarios multi-modal information fusion may be counterproductive. To facilitate its discussion, a new solution, MoETrack, with multiple tracking experts is proposed. It performs state-of-the-art on several benchmarks, including MV-RGBT, LasHeR, and VTUAV-ST.

(3) A new compositional perspective for method evaluation is provided by categorising MV-RGBT into two subsets, MV-RGBT-RGB and MV-RGBT-TIR, promoting a novel in-depth analysis and offering insightful recommendations for future developments in RGBT tracking.

ü´µFind our survey work at [repo](https://github.com/Zhangyong-Tang/Survey-for-MultiModal-Visual-Object-Tracking)

## Benchmark Data Comparison
### ‚≠ê Comparisons with Data in MV-RGBT and LasHeR

![1515eb339542550676a50a6d2c5aef6](https://github.com/user-attachments/assets/eb536543-5f25-4603-8fb0-e020350448f3)

Data examples from MV-RGBT
<img src="ER_Cat_Lawn0.gif" width="800">

<img src="ET_Fish_River02.gif" width="800">

## Qualitative comparisons
### Using a single modality in two typical MMW scenarios
![4c088edb97677cb0a51c7f192b2f1b7](https://github.com/user-attachments/assets/aae24dfa-9cd4-46e7-8251-7882c55cb0af)
### Using a single modality in two typical MMW scenarios

## The significane of MV-RGBT
- [x] Multi-modal vs. single-modal
- [x] RGB vs. TIR
![image](https://github.com/user-attachments/assets/88e8ca09-6505-4f91-9ea6-a1f9832d7089)

‚≠ê More detailed introduction of the proposed method, MoETrack, is available [here](https://github.com/Zhangyong-Tang/MoETrack)

